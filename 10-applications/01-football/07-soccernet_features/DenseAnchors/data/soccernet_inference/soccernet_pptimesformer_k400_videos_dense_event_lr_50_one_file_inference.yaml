MODEL: #MODEL field
    framework: "RecognizerTransformerDenseAnchors" #Mandatory, indicate the type of network, associate to the 'paddlevideo/modeling/framework/' .
    backbone: #Mandatory, indicate the type of backbone, associate to the 'paddlevideo/modeling/backbones/' .
        name: "VisionTransformer_tweaks" #Mandatory, The name of backbone.
        pretrained: "" # "" #"pretrained_weights/ppTimeSformer_k400_8f_distill.pdparams" #Optional, pretrained model path.
        img_size: 224
        patch_size: 16
        in_channels: 3
        embed_dim: 768
        depth: 12
        num_heads: 12
        mlp_ratio: 4
        qkv_bias: False
        epsilon: 1e-6
        num_seg: 16
        attention_type: 'divided_space_time'
    head:
        name: "ppTimeSformerAnchorHead" #Mandatory, indicate the type of head, associate to the 'paddlevideo/modeling/heads'
        num_classes: 18 #Optional, the number of classes to be classified.
        in_channels: 768 #input channel of the extracted feature.
        std: 0.02 #std value in params initialization
        # ls_eps: 0.1
        event_time_loss_weight: 5.0
        events_lr_multiplier: 50.0
        output_mode: "cls_score_event_times_features"  #output_mode: "features" "cls_score_event_times" # otherwise, save features
    runtime_cfg: # configuration used when the model is train or test.
        test: # test config
            num_seg: 16
            avg_type: 'prob' # 'score' or 'prob'

DATASET: #DATASET field
    batch_size: 1 #Mandatory, bacth size
    num_workers: 1 #Mandatory, XXX the number of subprocess on each GPU.
    test_batch_size: 1
    train:
        format: "VideoDenseAnchorsDataset" #Mandatory, indicate the type of dataset, associate to the 'paddlevidel/loader/dateset'
        data_prefix: ""
        file_path: "train.dense.list" #Mandatory, train data index file path
    valid:
        format: "VideoDenseAnchorsDataset" #Mandatory, indicate the type of dataset, associate to the 'paddlevidel/loader/dateset'
        data_prefix: ""
        file_path: "val.dense.list" #Mandatory, valid data index file path
    test:
        format: "VideoDenseAnchorsOneFileInferenceDataset" #Mandatory, indicate the type of dataset, associate to the 'paddlevidel/loader/dateset'
        data_prefix: ""
        file_path: "one_inference.json" #Mandatory, valid data index file path
        sample_length_secs: 5.0

PIPELINE: #PIPELINE field
    train: #Mandotary, indicate the pipeline to deal with the training data, associate to the 'paddlevideo/loader/pipelines/'
        decode:
            name: "VideoDecoder"
            backend: 'pyav'
            mode: 'train'
            num_seg: 16
        sample:
            name: "EventSampler"
            num_seg: 16
            seg_len: 1
            valid_mode: False
            sample_length_secs: 5.0
        transform: #Mandotary, image transform operator.
            - Normalization:
                mean: [0, 0, 0]
                std: [1, 1, 1]
                tensor_shape: [1, 1, 1, 3]
            - Image2Array:
                data_format: 'cthw'
            - JitterScale:
                min_size: 225
                max_size: 256
            - RandomCrop:
                target_size: 224
            - RandomFlip:

    valid: #Mandatory, indicate the pipeline to deal with the validing data. associate to the 'paddlevideo/loader/pipelines/'
        decode:
            name: "VideoDecoder"
            backend: 'pyav'
            mode: 'valid'
            num_seg: 16
        sample:
            name: "EventSampler"
            num_seg: 16
            seg_len: 1
            valid_mode: True
            sample_length_secs: 5.0
        transform:
            - Normalization:
                mean: [0, 0, 0]
                std: [1, 1, 1]
                tensor_shape: [1, 1, 1, 3]
            - Image2Array:
                data_format: 'cthw'
            - JitterScale:
                min_size: 224
                max_size: 224
            - CenterCrop:
                target_size: 224

    test:
        decode:
            name: "OneVideoDecoder"
            backend: 'pyav'
            mode: 'test'
            num_seg: 16
        sample:
            name: "OneFileSampler"
            num_seg: 16
            seg_len: 1
            valid_mode: True
            sample_length_secs: 5.0
        transform:
            - Normalization:
                mean: [0, 0, 0]
                std: [1, 1, 1]
                tensor_shape: [1, 1, 1, 3]
            - Image2Array:
                data_format: 'cthw'
            - JitterScale:
                min_size: 224
                max_size: 224
            - CenterCrop:
                target_size: 224
            # - UniformCrop:
            #     target_size: 224

OPTIMIZER: #OPTIMIZER field
    name: 'Momentum'
    momentum: 0.9
    learning_rate:
        iter_step: True
        name: 'CustomWarmupCosineDecay'
        max_epoch: 60
        warmup_epochs: 2
        warmup_start_lr: 0.00025
        cosine_base_lr: 0.0025
    weight_decay:
        name: 'L2'
        value: 0.00007
    use_nesterov: True
    grad_clip:
        name: 'ClipGradByGlobalNorm'
        value: 40.0

GRADIENT_ACCUMULATION:
    global_batch_size: 40 # Specify the sum of batches to be calculated by all GPUs

# MIX:
#     name: "VideoMix"
#     cutmix_prob: 0.5
#     mixup_alpha: 0.2
#     cutmix_alpha: 1.0

METRIC:
    name: 'CenterCropMetric'

INFERENCE:
    name: 'TimeSformer_Inference_helper'
    num_seg: 16
    target_size: 224
    mean: [0, 0, 0]
    std: [1, 1, 1]

model_name: "ppTimeSformer_dense_event_lr_50"
log_interval: 1 #Optional, the interal of logger, default:10
save_interval: 1
epochs: 60 #Mandatory, total epoch
log_level: "INFO" #Optional, the logger level. default: "INFO"
save_inference_results: True
inference_dir: '/mnt/storage/gait-0/xin/dev/PaddleVideo/temp/'